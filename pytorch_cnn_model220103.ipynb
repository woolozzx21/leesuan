{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNMDk0MP64kCU6/dkh3JSLk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woolozzx21/leesuan/blob/main/pytorch_cnn_model220103.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Tdtvt0caR2z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "transformation = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.1307),(0.3081,))])\n",
        "train_dataset = datasets.MNIST('data/', train=True, transform=transformation, download=True)\n",
        "test_dataset = datasets.MNIST('data/', train=False, transform=transformation, download=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_image(image):\n",
        "    image = image.numpy()[0]\n",
        "    mean=0.1307\n",
        "    std = 0.3081\n",
        "    image = ((mean*image)+std)\n",
        "    plt.imshow(image, cmap='gray')"
      ],
      "metadata": {
        "id": "WEOjbE3obXOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "evz4jYGpbYl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = next(iter(train_loader))\n",
        "plot_image(sample_data[0][1])"
      ],
      "metadata": {
        "id": "XpxdDG4iburW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_image(sample_data[0][2])"
      ],
      "metadata": {
        "id": "d2cHk8uxb5yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        " \n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x),2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320) #벡터로 핀다\n",
        "        x = F.relu(self.fc1(x)) #풀리커넥티드로 실행\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x) #풀리커넥티드\n",
        "        return F.log_softmax(x)  #\n"
      ],
      "metadata": {
        "id": "GRg6xb92cB5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(device, epoch, model, data_loader, optimizer, phase='training'):\n",
        "    if phase == 'training':\n",
        "        model.train() # 신경망 훈련상태 (dropout적용)\n",
        "    else:\n",
        "        model.eval() # 신경망 검증 상태 \n",
        "    running_loss = 0.0\n",
        "    running_correct = 0.0\n",
        "    for batch_idx, (data, target) in enumerate(data_loader): #(데이터, 목적)\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        if phase == 'training':\n",
        "            optimizer.zero_grad() # 모든 그라디언트 정보 날림\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target) # 로스 계산\n",
        "        running_loss +=  F.nll_loss(output, target, size_average=False).item()\n",
        "        preds = output.data.max(dim=1, keepdim=True)[1] \n",
        "        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum() # 같으면 true, 다른면 false\n",
        "        if phase == 'training':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    loss = running_loss / len(data_loader.dataset)\n",
        "    accuracy = 100.*running_correct/len(data_loader.dataset)\n",
        "    print(\"Phase: {}, Loss: {}, Accuracy: {}\".format(phase, loss, accuracy))\n",
        "    return loss, accuracy\n"
      ],
      "metadata": {
        "id": "X5D0keyXcNAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "\n",
        "model = Net()\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "train_loss, train_accuracy = [], []\n",
        "test_loss, test_accuracy = [], []\n",
        "for epoch in range(1, 21):\n",
        "    epoch_loss, epoch_accuracy = fit(DEVICE, epoch, model, train_loader, optimizer, 'training')\n",
        "    val_epoch_loss, val_epoch_accuracy = fit(DEVICE, epoch, model, test_loader, optimizer, 'validation')\n",
        "    train_loss.append(epoch_loss)\n",
        "    train_accuracy.append(epoch_accuracy)\n",
        "    test_loss.append(val_epoch_loss)\n",
        "    test_accuracy.append(val_epoch_accuracy)\n"
      ],
      "metadata": {
        "id": "Juq2OWNXfNV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(1, len(train_accuracy)+1), train_accuracy, 'bo', label='training accuracy')\n",
        "plt.plot(range(1, len(test_accuracy)+1), test_accuracy, 'r', label='test accuracy')\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "id": "djemEwHDfq3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(1, len(train_loss)+1), train_loss, 'bo', label='training loss')\n",
        "plt.plot(range(1, len(test_loss)+1), test_loss, 'r', label='test loss')\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "id": "v98L6ZIIjGeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4QOFVEMYk7at"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}